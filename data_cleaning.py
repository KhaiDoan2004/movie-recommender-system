"""
Script l√†m s·∫°ch v√† chu·∫©n h√≥a d·ªØ li·ªáu MovieLens
Th·ª±c hi·ªán c√°c t√°c v·ª•:
1. X·ª≠ l√Ω missing values
2. Chu·∫©n h√≥a d·ªØ li·ªáu (t√°ch year, genres, datetime)
3. Lo·∫°i b·ªè duplicates
4. Chu·∫©n b·ªã vector h√≥a (TF-IDF)
"""

import pandas as pd
import numpy as np
import re
from datetime import datetime
import os
from pathlib import Path

# ƒê∆∞·ªùng d·∫´n - relative t·ª´ project root
BASE_DIR = Path(__file__).parent.parent.parent
DATA_DIR = str(BASE_DIR / "data")
OUTPUT_DIR = str(BASE_DIR / "data_cleaned")

# T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a c√≥
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

def load_data():
    """Load d·ªØ li·ªáu g·ªëc"""
    print("=" * 80)
    print("LOADING DATA...")
    print("=" * 80)
    
    movies = pd.read_csv(os.path.join(DATA_DIR, "movies.csv"))
    ratings = pd.read_csv(os.path.join(DATA_DIR, "ratings.csv"))
    tags = pd.read_csv(os.path.join(DATA_DIR, "tags.csv"))
    links = pd.read_csv(os.path.join(DATA_DIR, "links.csv"))
    
    print("‚úÖ ƒê√£ load th√†nh c√¥ng!")
    return movies, ratings, tags, links

def clean_movies(movies):
    """
    L√†m s·∫°ch movies.csv
    1. X·ª≠ l√Ω missing genres
    2. T√°ch year t·ª´ title
    3. T√°ch genres th√†nh list
    """
    print("\n" + "=" * 80)
    print("L√ÄM S·∫†CH MOVIES.CSV")
    print("=" * 80)
    
    movies_clean = movies.copy()
    
    # 1. X·ª≠ l√Ω missing genres
    print("\n1. X·ª≠ l√Ω missing genres...")
    missing_genres_before = (movies_clean['genres'].isna() | 
                             (movies_clean['genres'] == '(no genres listed)')).sum()
    print(f"   - S·ªë phim kh√¥ng c√≥ genres tr∆∞·ªõc khi x·ª≠ l√Ω: {missing_genres_before}")
    
    # G√°n "Unknown" cho genres r·ªóng
    movies_clean['genres'] = movies_clean['genres'].fillna('Unknown')
    movies_clean.loc[movies_clean['genres'] == '(no genres listed)', 'genres'] = 'Unknown'
    
    missing_genres_after = (movies_clean['genres'] == 'Unknown').sum()
    print(f"   - S·ªë phim c√≥ genres 'Unknown' sau khi x·ª≠ l√Ω: {missing_genres_after}")
    
    # 2. T√°ch year t·ª´ title
    print("\n2. T√°ch year t·ª´ title...")
    def extract_year(title):
        """T√°ch nƒÉm t·ª´ title, v√≠ d·ª•: 'Toy Story (1995)' -> 1995"""
        match = re.search(r'\((\d{4})\)', str(title))
        if match:
            year = int(match.group(1))
            # Ki·ªÉm tra nƒÉm h·ª£p l√Ω (1900-2025)
            if 1900 <= year <= 2025:
                return year
        return None
    
    movies_clean['year'] = movies_clean['title'].apply(extract_year)
    movies_with_year = movies_clean['year'].notna().sum()
    print(f"   - S·ªë phim c√≥ year: {movies_with_year}/{len(movies_clean)}")
    print(f"   - Year min: {movies_clean['year'].min()}")
    print(f"   - Year max: {movies_clean['year'].max()}")
    
    # 3. T√°ch genres th√†nh list
    print("\n3. T√°ch genres th√†nh list...")
    movies_clean['genres_list'] = movies_clean['genres'].apply(
        lambda x: x.split('|') if pd.notna(x) and x != 'Unknown' else ['Unknown']
    )
    print(f"   - Sample genres_list: {movies_clean['genres_list'].iloc[0]}")
    
    # 4. T·∫°o title_clean (b·ªè year trong title)
    print("\n4. T·∫°o title_clean (b·ªè year)...")
    movies_clean['title_clean'] = movies_clean['title'].apply(
        lambda x: re.sub(r'\s*\(\d{4}\)\s*$', '', str(x)).strip()
    )
    print(f"   - Sample title: '{movies_clean['title'].iloc[0]}'")
    print(f"   - Sample title_clean: '{movies_clean['title_clean'].iloc[0]}'")
    
    print("\n‚úÖ Ho√†n th√†nh l√†m s·∫°ch movies!")
    return movies_clean

def clean_ratings(ratings):
    """
    L√†m s·∫°ch ratings.csv
    1. Lo·∫°i b·ªè duplicates (gi·ªØ b·∫£n cu·ªëi)
    2. Chuy·ªÉn timestamp ‚Üí datetime
    3. T·∫°o c√°c features th·ªùi gian
    """
    print("\n" + "=" * 80)
    print("L√ÄM S·∫†CH RATINGS.CSV")
    print("=" * 80)
    
    ratings_clean = ratings.copy()
    
    # 1. Lo·∫°i b·ªè duplicates
    print("\n1. Ki·ªÉm tra v√† lo·∫°i b·ªè duplicates...")
    duplicates_before = ratings_clean.duplicated(subset=['userId', 'movieId']).sum()
    print(f"   - S·ªë duplicates tr∆∞·ªõc khi x·ª≠ l√Ω: {duplicates_before}")
    
    if duplicates_before > 0:
        # Gi·ªØ b·∫£n ghi cu·ªëi c√πng (timestamp l·ªõn nh·∫•t)
        ratings_clean = ratings_clean.sort_values('timestamp')
        ratings_clean = ratings_clean.drop_duplicates(
            subset=['userId', 'movieId'], 
            keep='last'
        )
        print(f"   - ƒê√£ lo·∫°i b·ªè {duplicates_before} duplicates")
    else:
        print("   - Kh√¥ng c√≥ duplicates")
    
    # 2. Chuy·ªÉn timestamp ‚Üí datetime
    print("\n2. Chuy·ªÉn timestamp ‚Üí datetime...")
    ratings_clean['datetime'] = pd.to_datetime(ratings_clean['timestamp'], unit='s')
    print(f"   - Ng√†y s·ªõm nh·∫•t: {ratings_clean['datetime'].min()}")
    print(f"   - Ng√†y mu·ªôn nh·∫•t: {ratings_clean['datetime'].max()}")
    
    # 3. T·∫°o features th·ªùi gian
    print("\n3. T·∫°o features th·ªùi gian...")
    ratings_clean['year'] = ratings_clean['datetime'].dt.year
    ratings_clean['month'] = ratings_clean['datetime'].dt.month
    ratings_clean['day_of_week'] = ratings_clean['datetime'].dt.dayofweek
    print(f"   - ƒê√£ t·∫°o: year, month, day_of_week")
    
    print("\n‚úÖ Ho√†n th√†nh l√†m s·∫°ch ratings!")
    return ratings_clean

def clean_tags(tags):
    """
    L√†m s·∫°ch tags.csv
    1. X·ª≠ l√Ω missing tags
    2. Chu·∫©n h√≥a text (lower, strip)
    3. Chuy·ªÉn timestamp ‚Üí datetime
    """
    print("\n" + "=" * 80)
    print("L√ÄM S·∫†CH TAGS.CSV")
    print("=" * 80)
    
    tags_clean = tags.copy()
    
    # 1. X·ª≠ l√Ω missing tags
    print("\n1. X·ª≠ l√Ω missing tags...")
    missing_before = tags_clean['tag'].isna().sum()
    print(f"   - S·ªë tags missing tr∆∞·ªõc khi x·ª≠ l√Ω: {missing_before}")
    
    if missing_before > 0:
        # B·ªè c√°c d√≤ng c√≥ tag r·ªóng
        tags_clean = tags_clean.dropna(subset=['tag'])
        print(f"   - ƒê√£ b·ªè {missing_before} d√≤ng c√≥ tag r·ªóng")
    
    # 2. Chu·∫©n h√≥a text
    print("\n2. Chu·∫©n h√≥a text (lower, strip)...")
    tags_clean['tag'] = tags_clean['tag'].astype(str).str.lower().str.strip()
    print(f"   - Sample tag sau khi chu·∫©n h√≥a: '{tags_clean['tag'].iloc[0]}'")
    
    # 3. Chuy·ªÉn timestamp ‚Üí datetime
    print("\n3. Chuy·ªÉn timestamp ‚Üí datetime...")
    tags_clean['datetime'] = pd.to_datetime(tags_clean['timestamp'], unit='s')
    print(f"   - Ng√†y s·ªõm nh·∫•t: {tags_clean['datetime'].min()}")
    print(f"   - Ng√†y mu·ªôn nh·∫•t: {tags_clean['datetime'].max()}")
    
    print("\n‚úÖ Ho√†n th√†nh l√†m s·∫°ch tags!")
    return tags_clean

def aggregate_tags(tags_clean, movies_clean):
    """
    Aggregate tags theo movieId ƒë·ªÉ t·∫°o features cho content-based
    """
    print("\n" + "=" * 80)
    print("AGGREGATE TAGS THEO MOVIE")
    print("=" * 80)
    
    # Group tags theo movieId
    movie_tags = tags_clean.groupby('movieId')['tag'].apply(
        lambda x: ' '.join(x.unique())
    ).reset_index()
    movie_tags.columns = ['movieId', 'tags_combined']
    
    # Merge v·ªõi movies
    movies_with_tags = movies_clean.merge(movie_tags, on='movieId', how='left')
    movies_with_tags['tags_combined'] = movies_with_tags['tags_combined'].fillna('')
    
    print(f"   - S·ªë phim c√≥ tags: {movies_with_tags['tags_combined'].str.len().gt(0).sum()}")
    print(f"   - Sample tags_combined: '{movies_with_tags[movies_with_tags['tags_combined'].str.len() > 0]['tags_combined'].iloc[0][:100]}...'")
    
    return movies_with_tags

def prepare_content_features(movies_with_tags):
    """
    Chu·∫©n b·ªã features cho content-based recommendation
    T·∫°o text k·∫øt h·ª£p: title + genres + tags
    """
    print("\n" + "=" * 80)
    print("CHU·∫®N B·ªä CONTENT FEATURES")
    print("=" * 80)
    
    movies_features = movies_with_tags.copy()
    
    # T·∫°o text k·∫øt h·ª£p cho TF-IDF
    print("\n1. T·∫°o text k·∫øt h·ª£p (title + genres + tags)...")
    
    def combine_features(row):
        """K·∫øt h·ª£p title, genres, tags th√†nh m·ªôt text"""
        title = str(row['title_clean']) if pd.notna(row['title_clean']) else ''
        genres = ' '.join(row['genres_list']) if isinstance(row['genres_list'], list) else str(row['genres'])
        tags = str(row['tags_combined']) if pd.notna(row['tags_combined']) else ''
        
        # K·∫øt h·ª£p v·ªõi kho·∫£ng tr·∫Øng
        combined = f"{title} {genres} {tags}".strip()
        return combined
    
    movies_features['content_text'] = movies_features.apply(combine_features, axis=1)
    
    print(f"   - Sample content_text: '{movies_features['content_text'].iloc[0][:150]}...'")
    print(f"   - ƒê·ªô d√†i trung b√¨nh: {movies_features['content_text'].str.len().mean():.0f} k√Ω t·ª±")
    
    print("\n‚úÖ Ho√†n th√†nh chu·∫©n b·ªã content features!")
    return movies_features

def calculate_movie_stats(ratings_clean, movies_features):
    """
    T√≠nh th·ªëng k√™ cho m·ªói phim (avg_rating, num_ratings)
    """
    print("\n" + "=" * 80)
    print("T√çNH TH·ªêNG K√ä MOVIES")
    print("=" * 80)
    
    # T√≠nh average rating v√† s·ªë l∆∞·ª£ng ratings cho m·ªói phim
    movie_stats = ratings_clean.groupby('movieId').agg({
        'rating': ['mean', 'count']
    }).reset_index()
    
    movie_stats.columns = ['movieId', 'avg_rating', 'num_ratings']
    
    # Merge v·ªõi movies
    movies_with_stats = movies_features.merge(movie_stats, on='movieId', how='left')
    movies_with_stats['avg_rating'] = movies_with_stats['avg_rating'].fillna(0)
    movies_with_stats['num_ratings'] = movies_with_stats['num_ratings'].fillna(0).astype(int)
    
    print(f"   - S·ªë phim c√≥ rating: {movies_with_stats['num_ratings'].gt(0).sum()}")
    print(f"   - Rating trung b√¨nh: {movies_with_stats['avg_rating'].mean():.2f}")
    print(f"   - S·ªë ratings trung b√¨nh/phim: {movies_with_stats['num_ratings'].mean():.2f}")
    
    return movies_with_stats

def save_cleaned_data(movies_final, ratings_clean, tags_clean, links):
    """L∆∞u d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch"""
    print("\n" + "=" * 80)
    print("L∆ØU D·ªÆ LI·ªÜU ƒê√É L√ÄM S·∫†CH")
    print("=" * 80)
    
    # L∆∞u movies
    movies_output = movies_final[[
        'movieId', 'title', 'title_clean', 'genres', 'genres_list', 
        'year', 'tags_combined', 'content_text', 'avg_rating', 'num_ratings'
    ]]
    movies_output.to_csv(os.path.join(OUTPUT_DIR, "movies_cleaned.csv"), index=False)
    print(f"‚úÖ ƒê√£ l∆∞u: {OUTPUT_DIR}/movies_cleaned.csv ({len(movies_output)} d√≤ng)")
    
    # L∆∞u ratings
    ratings_output = ratings_clean[[
        'userId', 'movieId', 'rating', 'timestamp', 
        'datetime', 'year', 'month', 'day_of_week'
    ]]
    ratings_output.to_csv(os.path.join(OUTPUT_DIR, "ratings_cleaned.csv"), index=False)
    print(f"‚úÖ ƒê√£ l∆∞u: {OUTPUT_DIR}/ratings_cleaned.csv ({len(ratings_output)} d√≤ng)")
    
    # L∆∞u tags
    tags_output = tags_clean[[
        'userId', 'movieId', 'tag', 'timestamp', 'datetime'
    ]]
    tags_output.to_csv(os.path.join(OUTPUT_DIR, "tags_cleaned.csv"), index=False)
    print(f"‚úÖ ƒê√£ l∆∞u: {OUTPUT_DIR}/tags_cleaned.csv ({len(tags_output)} d√≤ng)")
    
    # L∆∞u links (kh√¥ng c·∫ßn l√†m s·∫°ch nhi·ªÅu)
    links.to_csv(os.path.join(OUTPUT_DIR, "links_cleaned.csv"), index=False)
    print(f"‚úÖ ƒê√£ l∆∞u: {OUTPUT_DIR}/links_cleaned.csv ({len(links)} d√≤ng)")

def summary(movies_final, ratings_clean, tags_clean):
    """T√≥m t·∫Øt k·∫øt qu·∫£ l√†m s·∫°ch"""
    print("\n" + "=" * 80)
    print("T√ìM T·∫ÆT K·∫æT QU·∫¢ L√ÄM S·∫†CH")
    print("=" * 80)
    
    print("\n‚úÖ ƒê√É HO√ÄN TH√ÄNH:")
    print("   1. ‚úÖ X·ª≠ l√Ω missing values (genres ‚Üí 'Unknown')")
    print("   2. ‚úÖ Chu·∫©n h√≥a d·ªØ li·ªáu:")
    print("      - T√°ch year t·ª´ title")
    print("      - T√°ch genres th√†nh list")
    print("      - Chuy·ªÉn timestamp ‚Üí datetime")
    print("      - Chu·∫©n h√≥a text (lower, strip)")
    print("   3. ‚úÖ Lo·∫°i b·ªè duplicates (n·∫øu c√≥)")
    print("   4. ‚úÖ Aggregate tags theo movie")
    print("   5. ‚úÖ T·∫°o content_text cho TF-IDF")
    print("   6. ‚úÖ T√≠nh th·ªëng k√™ movies (avg_rating, num_ratings)")
    
    print("\nüìä TH·ªêNG K√ä SAU KHI L√ÄM S·∫†CH:")
    print(f"   - Movies: {len(movies_final):,} phim")
    print(f"   - Ratings: {len(ratings_clean):,} ratings")
    print(f"   - Tags: {len(tags_clean):,} tags")
    print(f"   - Phim c√≥ genres 'Unknown': {(movies_final['genres'] == 'Unknown').sum()}")
    print(f"   - Phim c√≥ year: {movies_final['year'].notna().sum()}")
    print(f"   - Phim c√≥ tags: {movies_final['tags_combined'].str.len().gt(0).sum()}")
    print(f"   - Phim c√≥ rating: {movies_final['num_ratings'].gt(0).sum()}")
    
    print("\nüìã C√ÅC B∆Ø·ªöC TI·∫æP THEO:")
    print("   1. Tr·ª±c quan h√≥a d·ªØ li·ªáu (visualization.py)")
    print("   2. Vector h√≥a v·ªõi TF-IDF (s·∫Ω l√†m trong model)")
    print("   3. X√¢y d·ª±ng recommendation models")

def main():
    """H√†m ch√≠nh"""
    print("\n" + "=" * 80)
    print("L√ÄM S·∫†CH D·ªÆ LI·ªÜU MOVIELENS")
    print("=" * 80)
    
    # Load data
    movies, ratings, tags, links = load_data()
    
    # L√†m s·∫°ch t·ª´ng file
    movies_clean = clean_movies(movies)
    ratings_clean = clean_ratings(ratings)
    tags_clean = clean_tags(tags)
    
    # Aggregate tags
    movies_with_tags = aggregate_tags(tags_clean, movies_clean)
    
    # Chu·∫©n b·ªã content features
    movies_features = prepare_content_features(movies_with_tags)
    
    # T√≠nh th·ªëng k√™
    movies_final = calculate_movie_stats(ratings_clean, movies_features)
    
    # L∆∞u d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch
    save_cleaned_data(movies_final, ratings_clean, tags_clean, links)
    
    # T√≥m t·∫Øt
    summary(movies_final, ratings_clean, tags_clean)
    
    print("\n" + "=" * 80)
    print("HO√ÄN TH√ÄNH L√ÄM S·∫†CH D·ªÆ LI·ªÜU!")
    print("=" * 80)
    
    return movies_final, ratings_clean, tags_clean

if __name__ == "__main__":
    main()

